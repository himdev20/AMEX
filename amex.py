# -*- coding: utf-8 -*-
"""AMEX.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LJsyNuP3CG2xJlorazfuIQQyDYde5bm4
"""

import os
print(os.listdir())

# main.py

import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
import lightgbm as lgb
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
import gc
from datetime import timedelta

def load_data():
    """
    Load only the columns we use, then align dtypes for merging.
    """
    # Events (not used in this minimal example, but you can extend)
    events = pd.read_parquet(
        'add_event.parquet',
        engine='pyarrow',
        columns=['id2','id3','id6','id4','id7'],
        memory_map=True
    )

    # Transactions (optional for later features)
    trans = pd.read_parquet(
        'add_trans.parquet',
        engine='pyarrow',
        columns=['id2','f367','f368','f369','f370','f371','f372','f374','id8'],
        memory_map=True
    )

    # Offers metadata
    offers = pd.read_parquet(
        'offer_metadata.parquet',
        engine='pyarrow',
        columns=['id3','f375','f376','id12','id13'],
        memory_map=True
    )

    offers['id12'] = pd.to_datetime(offers['id12'])
    offers['id13'] = pd.to_datetime(offers['id13'])
    offers['diff'] = (offers['id13'] - offers['id12']).dt.days


    # Ensure id3 is string on both sides
    offers['id3'] = offers['id3'].astype(str)

    # Train data: includes y target
    train = pd.read_parquet(
        'train_data.parquet',
        engine='pyarrow',
        columns=['id1','id2','id3','id5','y'],
        memory_map=True
    )
    # Cast to string so it matches offers.id3
    train['id3'] = train['id3'].astype(str)

    # Test data
    test = pd.read_parquet(
        'test_data.parquet',
        engine='pyarrow',
        columns=['id1','id2','id3','id5'],
        memory_map=True
    )
    test['id3'] = test['id3'].astype(str)

    # Data dictionary (optional)
    data_dict = pd.read_csv('data_dictionary.csv')

    return train, test, events, trans, offers, data_dict

def prepare_features(df, offers):
    """
    Merge in offer‐level features:
      - f375 → redeem_freq
      - f376 → discount_rate
    """
    X = df.merge(offers, on='id3', how='left')
    X = df.merge(trans[['id3','f367']], on='id2', how='left')


    # Fill missing and coerce numeric
    X['f375'] = X['f375'].fillna(0).astype(float)
    X['f376'] = X['f376'].fillna(0).astype(float)

    # Rename to friendly names
    X = X.rename(columns={
        'f375': 'redeem_freq',
        'f376': 'discount_rate'
    })

    return X

# def train_model(train, offers):
#     """
#     Builds a simple logistic regression on two features.
#     """
#     data = prepare_features(train, offers)
#     X = data[['discount_rate','redeem_freq']]
#     y = train['y'].astype(int)

#     pipe = Pipeline([
#         ('scaler', StandardScaler()),
#         ('clf',   LogisticRegression(max_iter=200))
#     ])
#     pipe.fit(X, y)
#     return pipe

# def train_model(train, offers):
#     """
#     Train LightGBM classifier using offer features.
#     """
#     data = prepare_features(train, offers)
#     X = data[['discount_rate', 'redeem_freq','id3','f367','diff']]
#     y = train['y'].astype(int)

#     model = lgb.LGBMClassifier(
#         n_estimators=100,
#         learning_rate=0.1,
#         max_depth=6,
#         random_state=42
#     )
#     model.fit(X, y)
#     return model

# X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

import xgboost as xgb

# 1. Define feature columns and target
data = prepare_features(train, offers)
features = ['discount_rate', 'redeem_freq']
X = data[features]
y = train['y'].astype(int)

# 2. Create and train model
model = xgb.XGBClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    scale_pos_weight=(y == 0).sum() / (y == 1).sum(),
    objective='binary:logistic',
    eval_metric='auc',
    use_label_encoder=False,
    random_state=42
)
model.fit(X, y)

X_test = test[features]
test['pred'] = model.predict_proba(X_test)[:, 1]

# def make_submission(model, test, offers):
#     """
#     Scores test set, ranks per (id1,id2,id5), and writes top 7.
#     """
#     data = prepare_features(test, offers)
#     X = data[['discount_rate','redeem_freq']]
#     data['pred'] = model.predict_proba(X)[:,1]

#     # sort descending within each user/date
#     data = data.sort_values(
#         ['id1','id2','id5','pred'],
#         ascending=[True,True,True,False]
#     )

#     # pick top 7 per key
#     submission = (
#         data
#         .groupby(['id1','id2','id5'], group_keys=False)
#         .head(7)
#         [['id1','id2','id3','id5','pred']]
#     )

#     submission.to_csv(
#         'r2_submission_file_yourteam.csv',
#         index=False,
#         float_format='%.6f'
#     )
#     print("✅ Written r2_submission_file_yourteam.csv")


# def make_submission(model, test, offers):
#     """
#     Scores test set using LightGBM, ranks per (id1,id2,id5), and writes top 7.
#     """
#     data = prepare_features(test, offers)
#     X = data[['discount_rate', 'redeem_freq']]
#     data['pred'] = model.predict_proba(X)[:, 1]

#     data = data.sort_values(['id1', 'id2',  'pred'], ascending=[True, True, False])
#     submission = (
#         data
#         .groupby(['id1', 'id2'], group_keys=False)
#         .head(7)[['id1', 'id2', 'id3', 'id5', 'pred']]
#     )

#     submission.to_csv('r2_submission_file_yourteam.csv', index=False, float_format='%.6f')
#     print("✅ Written r2_submission_file_yourteam.csv")


submission = (
    test.sort_values(['id1', 'id2', 'pred'], ascending=[True, True, False])
        .groupby(['id1', 'id2'], group_keys=False)
        .head(7)[['id1', 'id2', 'id3', 'pred']]
)

submission.to_csv('xgb_submission.csv', index=False, float_format='%.6f')
print("✅ Saved xgb_submission.csv")

def main():
    train, test, events, trans, offers, data_dict = load_data()
    model = train_model(train, offers)
    make_submission(model, test, offers)


if __name__ == '__main__':
    main()